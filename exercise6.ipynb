{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07464b55",
   "metadata": {},
   "source": [
    "# Exercise 6 – Linking Opportunity Index & ACE Proxy\n",
    "\n",
    "In this exercise, you will examine how community opportunity factors relate to a proxy measure of **Adverse Childhood Experiences (ACEs)** using census tracts in New Jersey. You’ll build choropleth maps, compute simple composite indices, and explore correlations between measures of opportunity and a county‑level ACE proxy.\n",
    "\n",
    "A **choropleth map** is a thematic map where each geographic area is shaded according to a data value. By colouring tracts based on the child opportunity indicators, you can quickly identify spatial patterns – such as clusters of low opportunity around certain cities or counties. To make values comparable, we’ll standardize each indicator and map **z‑scores** (standard deviations) rather than raw values. All maps use quantile breaks (equal‑sized groups) and a shared legend indicating that higher z‑scores represent better opportunity.\n",
    "\n",
    "**Data sources**\n",
    "\n",
    "- **Child Opportunity Index (COI) 2.0** – tract‑level indicators that measure educational, environmental and socio‑economic opportunities for children. The raw indicators we will use (all oriented so higher values mean better opportunity) are:\n",
    "  - `ED_ECENROL` – early childhood (age 3–4) enrollment rate.\n",
    "  - `ED_HSGRAD` – high school on‑time graduation rate.\n",
    "  - `ED_MATH` – third‑grade math proficiency (NAEP scale).\n",
    "  - `HE_GREEN` – greenspace/park access index (treated here as a community factor).\n",
    "  - `SE_EMPRAT` – employment rate among working‑age adults.\n",
    "\n",
    "Data Source: diversitydatakids.org. (2020). Child Opportunity Index 2.0 census tract data. Brandeis University, The Heller School for Social Policy and Management. Retrieved from https://www.diversitydatakids.org/research-library/child-opportunity-index-20-census-tract-data \n",
    "\n",
    "- **Child welfare ACE proxy** – county‑level counts of child welfare cases (`cw_cases_count`) and under‑18 population (`under18_pop`) from the NJ Child Welfare Data Hub and the ACS. We derive `cw_cases_per_1000` (cases per 1 000 children) and its z‑score `cw_cases_per_1000_Z`. This serves as a proxy for ACE prevalence. **Important:** this value is identical for all tracts in a county, so any correlation with tract‑level indicators is driven by differences *between counties* rather than within them.\n",
    "\n",
    "Data source: New Jersey State Policy Lab. (n.d.). Child abuse and neglect dashboard. Rutgers University. Retrieved from https://njchilddata.rutgers.edu/portal/child-abuse-neglect\n",
    "\n",
    "The dataset `merged_data_plus_aceproxy_rate.geojson` already merges these sources and includes 2010 tract geometries. Before mapping and analysis we will:\n",
    "\n",
    "1. **Standardize** each COI indicator to a z‑score (subtract the NJ mean and divide by the standard deviation). Standardizing centres each variable at zero and puts different indicators on the same scale.  \n",
    "2. **Compute composite indices**: an education mini‑COI (`COI_edu_mini`) averaging the three education z‑scores, and an overall mini‑COI (`COI_mini`) averaging all five z‑scores.  \n",
    "3. **Create maps and plots**: make choropleth maps for your chosen variable (z‑score) and the composites, then create scatterplots comparing your variable and the composites to `cw_cases_per_1000_Z`, computing Pearson correlations.\n",
    "\n",
    "Each student in your group will pick one of the raw COI variables (two from the Education domain and two from the Social/Economic domain) and follow the same workflow for that variable. Change the `CASE_VAR` in the configuration cell below when it’s your turn to run the notebook. You’ll save your figures into a group‑specific folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e3514",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up a few variables that control your analysis.  \n",
    "- **GROUP_ID:** used to name your output files.  \n",
    "- **CASE_VAR:** the COI variable you’ve been assigned to analyse (`ED_ECENROL`, `ED_HSGRAD`, `ED_MATH`, `HE_GREEN`, or `SE_EMPRAT`).  \n",
    "- **ED_VARS** and **SE_VARS:** lists of the education and social/economic variables.  \n",
    "- **EXPORT_DIR:** the folder where your maps and plots will be saved.  \n",
    "- **MAP_QUANTILES:** number of quantile classes for choropleth maps.  \n",
    "- **SEED:** random seed for reproducibility in any stochastic steps (e.g. plotting jitter).\n",
    "\n",
    "Edit `CASE_VAR` (and optionally `GROUP_ID`) before running the notebook for your assigned variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b713985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working in Codespaces? Skip this cell.\n",
    "# Working in VS Code Jupyter notebook? Uncomment and run the following lines if you need to install these packages.\n",
    "\n",
    "# %pip install \"mapclassify>=2.4.0\"\n",
    "# %pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a25eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configuration: change CASE_VAR to your assigned variable when running your section\n",
    "GROUP_ID = \"G07\"  # Group identifier used in filenames\n",
    "\n",
    "# Define sets of variables for convenience\n",
    "actionvars_edu = [\"ED_ECENROL\", \"ED_HSGRAD\", \"ED_MATH\"]  # Education domain raw variables\n",
    "actionvars_se = [\"HE_GREEN\", \"SE_EMPRAT\"]  # Social/Economic domain raw variables\n",
    "\n",
    "# Combine names for full list of variables\n",
    "ED_VARS = actionvars_edu\n",
    "SE_VARS = actionvars_se\n",
    "\n",
    "EXPORT_DIR = \"figs_ex6_\" + GROUP_ID  # Directory for saving figures\n",
    "MAP_QUANTILES = 5  # Number of quantile classes for choropleth\n",
    "SEED = 4242  # Random seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be234811",
   "metadata": {},
   "source": [
    "### Group assignments\n",
    "\n",
    "Enter your assigned variable in the code cell below (set CASE_VAR = \"...\" and run).\n",
    "\n",
    "| Member   | Variable   | Description |\n",
    "|----------|------------|-------------|\n",
    "| Member 1 | `ED_HSGRAD` | high school on‑time graduation rate |\n",
    "| Member 2 | `ED_MATH`   | third‑grade math proficiency (NAEP scale) |\n",
    "| Member 3 | `SE_EMPRAT` | employment rate among working‑age adults |\n",
    "| Member 4 | `HE_GREEN`  | greenspace/park access index (treated here as a community factor) |\n",
    "\n",
    "Reminder: In the code cell below, set CASE_VAR to your assigned variable before running (e.g., CASE_VAR = \"ED_HSGRAD\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa045a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE_VAR =   # <-- set to your assigned variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72715c9",
   "metadata": {},
   "source": [
    "## Load Data & Quality Checks\n",
    "\n",
    "We load the GeoJSON file containing New Jersey census tracts along with the COI indicators and ACE proxy. It’s important to verify that the data are well‑formed before analysis:\n",
    "\n",
    "- **CRS check:** ensure the coordinate reference system is WGS 84 (EPSG: 4326).  \n",
    "- **Unique identifiers:** each census tract is identified by its `GEOID`. Confirm that there are no duplicates.  \n",
    "- **County broadcast check:** fields derived from the child welfare data (`cw_cases_count`, `cw_cases_per_1000`) should be constant for all tracts within the same county.  \n",
    "- **Missing values:** identify and drop tracts with missing values in any of the variables you will analyse.  \n",
    "- **Zero population:** drop any tracts with zero children under 18 so the ACE proxy isn’t undefined.\n",
    "\n",
    "Run the cell below to load the data and perform these checks. It will also print how many tracts are dropped due to missing data or zero population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged GeoJSON data\n",
    "# Make sure this file exists in the working directory or adjust the path accordingly\n",
    "gdf = gpd.read_file(\"merged_data_plus_aceproxy_rate.geojson\")\n",
    "\n",
    "# Print basic info\n",
    "print(\"Total tracts loaded:\", len(gdf))\n",
    "\n",
    "# Check coordinate system\n",
    "if gdf.crs is not None:\n",
    "    try:\n",
    "        epsg = gdf.crs.to_epsg()\n",
    "        print(\"CRS:\", gdf.crs)\n",
    "        print(\"CRS EPSG code:\", epsg)\n",
    "        if epsg != 4326:\n",
    "            raise ValueError(\"Data is not in EPSG:4326 as expected!\")\n",
    "    except Exception as e:\n",
    "        print(\"CRS to_epsg() not available or not numeric. Reported CRS:\", gdf.crs)\n",
    "\n",
    "# Check that GEOIDs are unique\n",
    "unique_ids = gdf[\"GEOID\"].nunique()\n",
    "if unique_ids != len(gdf):\n",
    "    raise ValueError(f\"Expected one row per tract, but found {unique_ids} unique GEOIDs for {len(gdf)} rows.\")\n",
    "\n",
    "# Verify county broadcast fields are constant within each county\n",
    "for col in [\"cw_cases_count\", \"cw_cases_per_1000\"]:\n",
    "    if col in gdf.columns:\n",
    "        vals_per_county = gdf.groupby(\"county_fips\")[col].nunique()\n",
    "        if vals_per_county.max() != 1:\n",
    "            problematic = vals_per_county[vals_per_county > 1]\n",
    "            print(f\"Warning: {col} has differing values within counties: {problematic.index.tolist()}\")\n",
    "        else:\n",
    "            print(f\"{col} is constant within each county (broadcast confirmed).\")\n",
    "\n",
    "# Drop tracts with no children (under18_pop <= 0)\n",
    "if \"under18_pop\" in gdf.columns:\n",
    "    no_kids = gdf[gdf[\"under18_pop\"] <= 0]\n",
    "    if len(no_kids) > 0:\n",
    "        print(f\"Dropping {len(no_kids)} tracts with no children (under18_pop <= 0).\")\n",
    "        gdf = gdf[gdf[\"under18_pop\"] > 0].copy()\n",
    "\n",
    "# Drop rows with missing values in variables of interest\n",
    "key_vars = ED_VARS + SE_VARS + [\"cw_cases_count\", \"cw_cases_per_1000\"]\n",
    "missing_report = {var: int(gdf[var].isna().sum()) for var in key_vars if var in gdf.columns}\n",
    "missing_any = any(count > 0 for count in missing_report.values())\n",
    "if missing_any:\n",
    "    print(\"Missing values detected:\", missing_report)\n",
    "    before_len = len(gdf)\n",
    "    gdf = gdf.dropna(subset=[var for var in key_vars if var in gdf.columns])\n",
    "    after_len = len(gdf)\n",
    "    print(f\"Dropped {before_len - after_len} tracts due to missing data in key variables.\")\n",
    "else:\n",
    "    print(\"No missing values detected in key variables.\")\n",
    "\n",
    "print(\"Data ready with\", len(gdf), \"tracts after cleaning.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbab0e",
   "metadata": {},
   "source": [
    "## Standardizing Variables\n",
    "\n",
    "To compare indicators measured on different scales, convert each to a z‑score: subtract the mean and divide by the standard deviation across all NJ tracts. The helper function `zify()` adds a `_<var>_Z` column to the GeoDataFrame if it doesn’t already exist. Missing values remain `NaN` so they don’t influence the mean or standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0995d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zify(df, var):\n",
    "    \"\"\"Compute and add a z‑score column for `var` in `df` (new column named `<var>_Z`).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame or geopandas.GeoDataFrame\n",
    "        The data structure to which the z‑score column will be added.\n",
    "    var : str\n",
    "        Name of the variable to standardize.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The name of the z‑score column.\n",
    "    \"\"\"\n",
    "    z_col = var + \"_Z\"\n",
    "    if z_col in df.columns:\n",
    "        return z_col\n",
    "    series = df[var]\n",
    "    mean_val = series.mean(skipna=True)\n",
    "    std_val = series.std(skipna=True)\n",
    "    if std_val is None or std_val == 0:\n",
    "        raise ValueError(f\"Standard deviation for {var} is zero or undefined; cannot compute z‑score.\")\n",
    "    df[z_col] = (series - mean_val) / std_val\n",
    "    return z_col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e5aca5",
   "metadata": {},
   "source": [
    "### Standardize Variables & Build Mini‑COI\n",
    "\n",
    "Run the next cell to create z‑score versions of all COI indicators listed in `ED_VARS` and `SE_VARS`, as well as the ACE proxy rate. Then compute two simple composite indices:\n",
    "\n",
    "- `COI_edu_mini` – the mean of the education z‑scores (`ED_ECENROL_Z`, `ED_HSGRAD_Z`, `ED_MATH_Z`).\n",
    "- `COI_SE_mini` – the mean of the social/economic z‑scores (`HE_GREEN_Z` and `SE_EMPRAT_Z`).\n",
    "\n",
    "These \"mini COI\" measures approximate the official COI domain scores by equally weighting each standardized indicator within their respective domains. We also save a small JSON file documenting exactly which z‑score columns were averaged in each composite for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7890465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize COI variables\n",
    "for var in ED_VARS + SE_VARS:\n",
    "    if var in gdf.columns:\n",
    "        zify(gdf, var)\n",
    "\n",
    "# Standardize the ACE proxy rate\n",
    "if \"cw_cases_per_1000\" in gdf.columns:\n",
    "    zify(gdf, \"cw_cases_per_1000\")\n",
    "\n",
    "# Compute mini COI composites\n",
    "edu_components = [f\"{v}_Z\" for v in ED_VARS]\n",
    "se_components = [f\"{v}_Z\" for v in SE_VARS]\n",
    "\n",
    "# Check that all z‑score columns exist\n",
    "for col in edu_components + se_components:\n",
    "    if col not in gdf.columns:\n",
    "        raise KeyError(f\"Expected z‑score column {col} missing; ensure variables were standardized.\")\n",
    "\n",
    "# Education mini index\n",
    "gdf[\"COI_edu_mini\"] = gdf[edu_components].mean(axis=1)\n",
    "\n",
    "# Social/Economic mini index\n",
    "gdf[\"COI_SE_mini\"] = gdf[se_components].mean(axis=1)\n",
    "\n",
    "# Save recipe for reproducibility\n",
    "mini_coi_recipe = {\n",
    "    \"COI_edu_mini\": edu_components,\n",
    "    \"COI_SE_mini\": se_components,\n",
    "    \"note\": \"All components are oriented so higher = better before averaging.\"\n",
    "}\n",
    "\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "import json\n",
    "with open(os.path.join(EXPORT_DIR, f\"{GROUP_ID}_mini_coi_recipe.json\"), \"w\") as f:\n",
    "    json.dump(mini_coi_recipe, f, indent=2)\n",
    "\n",
    "print(\"Composite indices computed and recipe saved to\", os.path.join(EXPORT_DIR, f\"{GROUP_ID}_mini_coi_recipe.json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6f9c0",
   "metadata": {},
   "source": [
    "## Choropleth Maps\n",
    "\n",
    "To visualize spatial patterns, we'll create choropleth maps for:\n",
    "\n",
    "- Your selected variable's z‑score (`<CASE_VAR>_Z`).  \n",
    "- The education mini‑COI (`COI_edu_mini`).  \n",
    "- The social/economic mini‑COI (`COI_SE_mini`).  \n",
    "- *(Optional)* the raw variable and the ACE proxy z‑score (`cw_cases_per_1000_Z`).\n",
    "\n",
    "All maps use five quantile classes (defined by `MAP_QUANTILES`) and share a consistent legend that reads \"z‑score (SD): higher = better\". County boundaries are drawn to emphasize that the ACE proxy is constant within each county. Running the following cell will produce and save the maps to the directory specified by `EXPORT_DIR`. Adjust the colour map or figure size if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ensure export dir exists\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "# We’ll use the full GeoJSON from gdf; Folium likes WGS84 (EPSG:4326), which you already have.\n",
    "# Small helper to compute quantile bins robustly (no mapclassify needed)\n",
    "def _quantile_bins(series, k=5):\n",
    "    # dropna and compute quantiles; make sure edges are strictly increasing\n",
    "    q = np.linspace(0, 1, k + 1)\n",
    "    vals = np.nanquantile(series.dropna(), q)\n",
    "    # Ensure uniqueness (np.nanquantile can return repeats with discrete data)\n",
    "    eps = 1e-9\n",
    "    for i in range(1, len(vals)):\n",
    "        if vals[i] <= vals[i-1]:\n",
    "            vals[i] = vals[i-1] + eps\n",
    "    return list(vals)\n",
    "\n",
    "def _nice_center(gdf_):\n",
    "    # rough center of New Jersey; fallback to lat/lon mean if geometry bounds fail\n",
    "    try:\n",
    "        minx, miny, maxx, maxy = gdf_.total_bounds\n",
    "        return [(miny+maxy)/2, (minx+maxx)/2]\n",
    "    except Exception:\n",
    "        return [40.06, -74.4]\n",
    "\n",
    "def interactive_choropleth(column, title, html_filename, bins=None, fill_color=\"Blues\",\n",
    "                           legend_title=\"z-score (SD) [higher = better]\"):\n",
    "    # Compute bins if not provided\n",
    "    if bins is None:\n",
    "        bins = _quantile_bins(gdf[column], k=MAP_QUANTILES)\n",
    "\n",
    "    # Base map (students can zoom/pan)\n",
    "    m = folium.Map(location=_nice_center(gdf), zoom_start=8, tiles=\"cartodbpositron\")\n",
    "\n",
    "    # Choropleth layer\n",
    "    chor = folium.Choropleth(\n",
    "        geo_data=gdf.to_json(),            # full tract geometries + properties\n",
    "        data=gdf,                          # DataFrame with values\n",
    "        columns=[\"GEOID\", column],         # bind by GEOID\n",
    "        key_on=\"feature.properties.GEOID\",\n",
    "        fill_color=fill_color,\n",
    "        fill_opacity=0.85,\n",
    "        line_opacity=0.2,\n",
    "        line_color=\"gray\",\n",
    "        bins=bins,\n",
    "        nan_fill_opacity=0.0,\n",
    "        legend_name=legend_title,          # appears as legend title\n",
    "        smooth_factor=0.5,\n",
    "        name=title\n",
    "    )\n",
    "    chor.add_to(m)\n",
    "\n",
    " # Hover tooltip with tract + county + value (keep geometry!)\n",
    "    try:\n",
    "        tooltip_gdf = gdf[[\"GEOID\", \"county_fips\", column, gdf.geometry.name]].rename(columns={column: \"value\"})\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"Column '{column}' not found in GeoDataFrame.\")\n",
    "    tooltip = folium.features.GeoJson(\n",
    "        data=tooltip_gdf,  # pass a GeoDataFrame (with geometry), not a JSON string\n",
    "        name=\"tooltip\",\n",
    "        style_function=lambda x: {\"color\": \"transparent\", \"fillOpacity\": 0},\n",
    "        highlight_function=lambda x: {\"weight\": 2, \"color\": \"black\", \"fillOpacity\": 0.1},\n",
    "        tooltip=folium.features.GeoJsonTooltip(\n",
    "            fields=[\"GEOID\", \"county_fips\", \"value\"],\n",
    "            aliases=[\"GEOID\", \"County FIPS\", f\"{column}\"],\n",
    "            localize=True,\n",
    "            sticky=False,\n",
    "            labels=True,\n",
    "        ),\n",
    "    )\n",
    "    tooltip.add_to(m)\n",
    "\n",
    "    # Optional: label county FIPS at centroids (lightweight text annotations)\n",
    "    try:\n",
    "        counties = gdf.dissolve(by=\"county_fips\")\n",
    "        counties[\"cx\"] = counties.geometry.centroid.y\n",
    "        counties[\"cy\"] = counties.geometry.centroid.x\n",
    "        for fips, row in counties.iterrows():\n",
    "            folium.map.Marker(\n",
    "                [row[\"cx\"], row[\"cy\"]],\n",
    "                icon=folium.DivIcon(\n",
    "                    html=f'<div style=\"font-size:10px;color:black;opacity:0.8\">{fips}</div>'\n",
    "                ),\n",
    "            ).add_to(m)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    folium.LayerControl(collapsed=True).add_to(m)\n",
    "    out_path = os.path.join(EXPORT_DIR, html_filename)\n",
    "    m.save(out_path)\n",
    "    print(\"Saved interactive map →\", out_path)\n",
    "\n",
    "# === BUILD INTERACTIVE MAPS ===\n",
    "given_var = CASE_VAR\n",
    "z_var = f\"{CASE_VAR}_Z\"\n",
    "\n",
    "# CASE var (Z)\n",
    "interactive_choropleth(\n",
    "    column=z_var,\n",
    "    title=f\"{given_var} (Z-score) by Tract\",\n",
    "    html_filename=f\"{GROUP_ID}_{given_var}_Z_map.html\",\n",
    "    fill_color=\"Blues\",\n",
    "    legend_title=\"z-score (SD) [higher = better]\"\n",
    ")\n",
    "\n",
    "# Education mini-COI\n",
    "interactive_choropleth(\n",
    "    column=\"COI_edu_mini\",\n",
    "    title=\"COI_edu_mini (Education Opportunity Index)\",\n",
    "    html_filename=f\"{GROUP_ID}_COI_edu_mini_map.html\",\n",
    "    fill_color=\"Blues\",\n",
    "    legend_title=\"z-score (SD) [higher = better]\"\n",
    ")\n",
    "\n",
    "# Social/Economic mini-COI\n",
    "interactive_choropleth(\n",
    "    column=\"COI_SE_mini\",\n",
    "    title=\"COI_SE_mini (Social/Economic Opportunity Index)\",\n",
    "    html_filename=f\"{GROUP_ID}_COI_SE_mini_map.html\",\n",
    "    fill_color=\"Blues\",\n",
    "    legend_title=\"z-score (SD) [higher = better]\"\n",
    ")\n",
    "\n",
    "# Optional: ACE proxy map (county-broadcast; different palette and legend title)\n",
    "# interactive_choropleth(\n",
    "#     column=\"cw_cases_per_1000_Z\",\n",
    "#     title=\"Child Welfare Case Rate (Z) by Tract (County-level)\",\n",
    "#     html_filename=f\"{GROUP_ID}_ACEproxy_map.html\",\n",
    "#     fill_color=\"OrRd\",\n",
    "#     legend_title=\"ACE proxy z-score (SD) [higher = more cases]\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfed07a",
   "metadata": {},
   "source": [
    "## ✅ Complete Table 1 (use your assigned variable)\n",
    "\n",
    "### 1) Pick one tract and report its z-score (for item 1 in Table 1)\n",
    "Open your group’s **interactive choropleth HTML map** (saved in your `EXPORT_DIR`).  \n",
    "**Zoom in** on a neighborhood and **click one census tract.**  \n",
    "The popup will show:\n",
    "\n",
    "- **GEOID** (the 11-digit census-tract ID)  \n",
    "- **County FIPS** code  \n",
    "- your variable’s **z-score** (for example: `ED_HSGRAD_Z = −1.706`)  \n",
    "\n",
    "Record that GEOID and z-score. Interpret it in plain language in ≤ 280 characters (± SD from NJ mean + approximate percentile).  \n",
    "\n",
    "> Example popup (what you’ll see when you click a tract):  \n",
    "> ![Example tract popup with GEOID and z-score](zscoredemo.png)\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Use these short primers to answer the COI “composition & calculation” prompts (questions 2 and 3 in Table 1)\n",
    "These summarize how the **official Child Opportunity Index (COI) 2.0** builds its domain composites.  \n",
    "Our classroom mini-COIs are simplified teaching versions—use these notes for comparison.\n",
    "\n",
    "#### COI 2.0 in one paragraph\n",
    "COI 2.0 measures child-relevant neighborhood opportunity using **29 indicators** grouped into **three domains**—**Education**, **Health & Environment**, and **Social & Economic**—for all U.S. census tracts.  \n",
    "Each indicator is **z-scored** (2010 baseline) and direction-aligned so that higher = more opportunity.  \n",
    "Indicators are then **weighted** (not equally) based on their average association with independent health and economic outcomes.  \n",
    "Weighted indicators form domain scores; the overall COI aggregates those domains with the same evidence-based weighting.  \n",
    "Child Opportunity Levels (Very Low → Very High) correspond to percentile groups of these standardized domain / overall scores.\n",
    "\n",
    "#### Education Domain – What it Measures & How it’s Combined\n",
    "- **Indicators:** early-childhood education access & enrollment, 3rd-grade reading and math proficiency, on-time high-school graduation, AP course participation, nearby college enrollment, school poverty (reversed), teacher experience (reversed), and adult educational attainment.  \n",
    "- **Computation:** each indicator → z-score (2010), direction reversed where needed, then assigned a data-driven weight according to its predictive strength; weighted indicators sum to the Education domain score.  \n",
    "- **Our mini version:**  \n",
    "  `COI_edu_mini = mean(ED_ECENROL_Z, ED_HSGRAD_Z, ED_MATH_Z)` (equal weights; higher = better).\n",
    "\n",
    "#### Social & Economic Domain – What it Measures & How it’s Combined\n",
    "- **Indicators:** economic resources and family structure factors—employment rate, long commute share (reversed), single-parent household share (reversed), plus an **Economic Resource Index** combining poverty, public assistance, homeownership, high-skill employment, and median household income via principal components analysis (PCA).  \n",
    "- **Computation:** z-score each indicator, align direction, apply empirical weights from predictive models, and sum to the Social & Economic domain score.  \n",
    "- **Our mini COI version**\n",
    "  `COI_SE_mini = mean(HE_GREEN_Z, SE_EMPRAT_Z)` (equal weights; higher = better).  \n",
    "  *Note:* The official Social & Economic domain includes more socioeconomic measures (poverty, income, housing, family structure) and weighted aggregation for greater validity.\n",
    "---\n",
    "\n",
    "### Learn more (official source)\n",
    "**Child Opportunity Index 2.0 – Technical Documentation** (education & social/economic indicator lists, standardization, PCA economic resource index, weighting and aggregation details):  \n",
    "https://www.diversitydatakids.org/sites/default/files/2020-02/ddk_coi2.0_technical_documentation_20200212.pdf\n",
    "\n",
    "*Footnote:* `COI_edu_mini` = mean(ED_ECENROL_Z, ED_HSGRAD_Z, ED_MATH_Z); `COI_SE_mini` = mean(HE_GREEN_Z, SE_EMPRAT_Z). Higher = better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c866b7",
   "metadata": {},
   "source": [
    "## Scatterplots & Correlation\n",
    "\n",
    "In Part 2 you will explore the relationship between opportunity indicators and the ACE proxy. The expectation is a **negative correlation** – higher opportunity should be associated with fewer child welfare cases. Each student will produce:\n",
    "\n",
    "- **Scatter A:** your chosen variable’s z‑score (`<CASE_VAR>_Z`) against `cw_cases_per_1000_Z`, including a fitted linear regression line and labels for Pearson *r* and *r²*.\n",
    "- **Scatter B:** the education composite (`COI_edu_mini`) against `cw_cases_per_1000_Z` (same for everyone; generate it once).\n",
    "- **Scatter C:** the overall composite (`COI_mini`) against `cw_cases_per_1000_Z`.\n",
    "\n",
    "Because the ACE proxy is constant within each county, the correlation you observe is entirely due to differences **between counties**. You can compute a between‑county correlation by aggregating tracts to county means. The code below generates the scatterplots, annotates the correlation coefficients, and optionally calculates the county‑level correlation for your variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Prepare variables\n",
    "x_var = CASE_VAR + \"_Z\"\n",
    "y_var = \"cw_cases_per_1000_Z\"\n",
    "\n",
    "# Function to create a scatter plot with regression line and correlation annotation\n",
    "def scatter_with_corr(x_data, y_data, xlabel, ylabel, title, filename):\n",
    "    fig, ax = plt.subplots(figsize=(5.5, 5.5))\n",
    "    sns.regplot(x=x_data, y=y_data, ci=None, scatter_kws={\"alpha\": 0.5}, line_kws={\"color\": \"red\"}, ax=ax)\n",
    "    # Compute correlation\n",
    "    mask = ~x_data.isna() & ~y_data.isna()\n",
    "    r = np.corrcoef(x_data[mask], y_data[mask])[0, 1]\n",
    "    r2 = r ** 2\n",
    "    ax.text(0.97, 0.03, f\"r = {r:.2f}, r² = {r2:.2f}\", transform=ax.transAxes,\n",
    "            horizontalalignment='right', verticalalignment='bottom', fontsize=11,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", alpha=0.8))\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(EXPORT_DIR, filename), dpi=150)\n",
    "    plt.close(fig)\n",
    "    return r\n",
    "\n",
    "# Scatter A: CASE_VAR_Z vs ACE proxy\n",
    "r_case = scatter_with_corr(gdf[x_var], gdf[y_var], f\"{CASE_VAR} (Z-score)\", \"Child Welfare Cases per 1000 (Z-score)\",\n",
    "                          f\"{CASE_VAR}_Z vs Child Welfare Case Rate (Z)\", f\"{GROUP_ID}_scatter_{CASE_VAR}.png\")\n",
    "print(f\"Scatter plot saved for {CASE_VAR}_Z vs {y_var} with r = {r_case:.2f}.\")\n",
    "\n",
    "# Scatter B: COI_edu_mini vs ACE proxy\n",
    "r_edu = scatter_with_corr(gdf[\"COI_edu_mini\"], gdf[y_var], \"COI_edu_mini (Mean Education Z)\",\n",
    "                          \"Child Welfare Cases per 1000 (Z-score)\", \"COI_edu_mini vs Child Welfare Case Rate (Z)\",\n",
    "                          f\"{GROUP_ID}_scatter_COI_edu_mini.png\")\n",
    "print(f\"Scatter plot saved for COI_edu_mini vs {y_var} with r = {r_edu:.2f}.\")\n",
    "\n",
    "# Scatter C: COI_SE_mini vs ACE proxy\n",
    "r_se = scatter_with_corr(gdf[\"COI_SE_mini\"], gdf[y_var], \"COI_SE_mini (Mean Social/Economic Z)\",\n",
    "                         \"Child Welfare Cases per 1000 (Z-score)\", \"COI_SE_mini vs Child Welfare Case Rate (Z)\",\n",
    "                         f\"{GROUP_ID}_scatter_COI_SE_mini.png\")\n",
    "print(f\"Scatter plot saved for COI_SE_mini vs {y_var} with r = {r_se:.2f}.\")\n",
    "\n",
    "# Optional: between-county correlation (aggregated by county)\n",
    "county_means = gdf.groupby(\"county_fips\")[[x_var, y_var]].mean()\n",
    "if county_means[x_var].std() > 0:\n",
    "    r_between = county_means[x_var].corr(county_means[y_var])\n",
    "    print(f\"Between-county correlation for {CASE_VAR}_Z: r_between = {r_between:.2f}\")\n",
    "else:\n",
    "    print(\"No variation in the predictor across counties; cannot compute between-county correlation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200d60c1",
   "metadata": {},
   "source": [
    "### Optional: Compile Correlation Metrics\n",
    "\n",
    "You can compile correlation metrics for all standardized variables and the composite indices, both at the tract level and aggregated by county. The following cell builds a simple DataFrame of correlations (*r* and *r²*) for each predictor against the ACE proxy, writes it to a CSV, and displays the first few rows. This is helpful for ranking variables by the strength of their association with ACE rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile correlation metrics across variables and composites\n",
    "metrics = []\n",
    "\n",
    "# List all z-score predictors\n",
    "predictors = [f\"{v}_Z\" for v in ED_VARS + SE_VARS] + [\"COI_edu_mini\", \"COI_SE_mini\"]\n",
    "\n",
    "for pred in predictors:\n",
    "    # Tract-level correlation\n",
    "    r_all = gdf[pred].corr(gdf[\"cw_cases_per_1000_Z\"])\n",
    "    metrics.append({\n",
    "        \"predictor\": pred,\n",
    "        \"level\": \"tracts_all\",\n",
    "        \"N\": len(gdf),\n",
    "        \"r\": round(r_all, 3),\n",
    "        \"r2\": round(r_all**2, 3)\n",
    "    })\n",
    "    # County-level correlation (aggregate means)\n",
    "    county_vals = gdf.groupby(\"county_fips\")[[pred, \"cw_cases_per_1000_Z\"]].mean()\n",
    "    r_cnty = county_vals[pred].corr(county_vals[\"cw_cases_per_1000_Z\"])\n",
    "    metrics.append({\n",
    "        \"predictor\": pred,\n",
    "        \"level\": \"county_means\",\n",
    "        \"N\": len(county_vals),\n",
    "        \"r\": round(r_cnty, 3) if r_cnty is not None else None,\n",
    "        \"r2\": round(r_cnty**2, 3) if r_cnty is not None else None\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_csv_path = os.path.join(EXPORT_DIR, f\"{GROUP_ID}_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "print(\"Saved correlation metrics to\", metrics_csv_path)\n",
    "\n",
    "# Display first few rows\n",
    "metrics_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e49e63",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Complete remaining Working Tables in shared slides and group comparison questions!\n",
    "- Follow submission directions on Canvas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
